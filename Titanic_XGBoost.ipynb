################################################################################
# Jupyter Notebook: Titanic Survival Prediction using XGBoost (Updated)
################################################################################

# In[1]: Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import xgboost as xgb
import warnings

# OPTIONAL: to hide the FutureWarning related to __sklearn_tags__
warnings.filterwarnings('ignore', category=FutureWarning)

################################################################################
# In[2]: Load the data
################################################################################
url = 'https://drive.google.com/uc?export=download&id=1Oytm0kGCmWsydZrRvCyK_cOE2WfnaVIA'
titanic_col_names = [
    'PassengerID',
    'Survived',
    'Pclass',
    'Name',
    'Sex',
    'Age',
    'SibSp',
    'Parch',
    'Ticket',
    'Fare',
    'Embarked'
]
titanic = pd.read_csv(url, header=0, names=titanic_col_names)

print("Shape of the dataset:", titanic.shape)
titanic.head()

################################################################################
# In[3]: Data Cleaning & Feature Engineering
################################################################################

# 1. Check for missing values
print("\nMissing values before cleaning:")
print(titanic.isnull().sum())

# 2. Fill missing 'Age' with median
titanic['Age'] = titanic['Age'].fillna(titanic['Age'].median())

# 3. Fill missing 'Embarked' with the most common value (e.g., 'S')
titanic['Embarked'] = titanic['Embarked'].fillna('S')

# 4. Convert 'Sex' to numeric (male=1, female=0)
titanic['Sex'] = titanic['Sex'].map({'male': 1, 'female': 0})

# 5. Convert 'Embarked' to numeric labels (S=0, C=1, Q=2)
embarked_map = {'S': 0, 'C': 1, 'Q': 2}
titanic['Embarked'] = titanic['Embarked'].map(embarked_map)

# 6. Fill any remaining missing 'Fare' if present (using median)
titanic['Fare'] = titanic['Fare'].fillna(titanic['Fare'].median())

print("\nMissing values after cleaning:")
print(titanic.isnull().sum())

################################################################################
# In[4]: Prepare features (X) and target (y)
################################################################################
features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']
X = titanic[features]
y = titanic['Survived']

print("\nFeature matrix shape:", X.shape)
print("Target vector shape:", y.shape)

################################################################################
# In[5]: Train-test split
################################################################################
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print("\nTraining set size:", X_train.shape[0])
print("Test set size:", X_test.shape[0])

################################################################################
# In[6]: Build and train an XGBoost model
################################################################################

# Create the XGBClassifier without 'use_label_encoder'
model = xgb.XGBClassifier(
    n_estimators=100,
    max_depth=3,
    learning_rate=0.1,
    random_state=42,
    eval_metric='logloss'  # Note: 'logloss' is good for binary classification
)

# Fit the model
model.fit(X_train, y_train)

# Optional: Print the model to see its parameters
# (instead of letting Jupyter automatically display it)
print("Training complete. Model:\n", model)

################################################################################
# In[7]: Make predictions on the test set
################################################################################
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"\nAccuracy on the test set: {accuracy:.4f}")

################################################################################
# In[8]: Determine the number of predicted survivors and their PassengerIDs
################################################################################
test_df = titanic.iloc[X_test.index].copy()
test_df['PredictedSurvived'] = y_pred

num_survivors = test_df['PredictedSurvived'].sum()
print(f"\nNumber of survivors predicted in the test set: {num_survivors}")

survived_passenger_ids = test_df.loc[test_df['PredictedSurvived'] == 1, 'PassengerID'].values
print("\nPassenger IDs predicted to survive:")
print(survived_passenger_ids)

# Group by Pclass and compute mean survival
survival_by_class = titanic.groupby('Pclass')['Survived'].mean()
print("Survival rate by passenger class:\n", survival_by_class)


# Compare fare distributions for survivors vs. nonsurvivors
fare_stats = titanic.groupby('Survived')['Fare'].median()
print("\nMedian fare for survivors vs. nonsurvivors:\n", fare_stats)


correlation = titanic['Fare'].corr(titanic['Survived'])
print("\nCorrelation between Fare and Survived:", correlation)
